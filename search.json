[
  {
    "objectID": "index.html#minha-motivação",
    "href": "index.html#minha-motivação",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "Minha Motivação ",
    "text": "Minha Motivação \nEm um vídeo de um físico americano muito famoso, Richard Feynman diz que toda explicação depende de um quadro de referência compartilhado entre quem pergunta e quem responde.\nAntes de responder por que algo acontece, é preciso concordar sobre o que já sabemos ser verdade.\nÉ aí que mora o perigo. A maioria das pessoas ainda não está confortável com (e ainda não domina) a formalização matemática e estatística que está atrás de muito fenômeno, inclusive no mundo dos dados. Portanto, é nesse gap que entra a minha filosofia de ensino. Eu quero te convencer que:\n\nVocê é capaz sim de entender coisas complexas, mas precisa de alguém capaz de traduzi-las para o seu quadro de referência atual\nVocê é capaz sim de expandir seu quadro de referência atual, para poder ter espaço para colocar as verdadeiras respostas das suas possíveis perguntas.\n\nÉ exatamente assim com a Regressão Linear — e com a Ciência de Dados em geral.\nQuando alguém pergunta “por que o modelo funciona?”, a resposta exige atravessar várias camadas: álgebra linear, probabilidade, inferência, otimização.\n\nSe você não conhece essas bases, a explicação soa misteriosa ou com certeza eu estarei trapaceando para te responder;\n\nSe você conhece, ela se torna óbvia, elegante e te empodera no longo prazo.\n\nEste curso nasce dessa motivação:\n\nCriar um caminho que reconstrói o quadro conceitual para que a matemática e estatística passem a fazer sentido.\n\n\n“Entender é compartilhar o mesmo vocabulário da explicação e pressupõe que conseguimos atingir o mesmo quadro de referência.”"
  },
  {
    "objectID": "index.html#exemplo",
    "href": "index.html#exemplo",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "Exemplo",
    "text": "Exemplo\nAluno:\n- “Caio, por que a Regressão Linear funciona? Por que a gente usa isso?”\nEu (sorrindo):\n- “Depende do que você quer dizer com”funciona”. - Se você quer dizer ‘por que a reta se ajusta aos pontos’, então estamos falando de álgebra linear e geometria. - Se você quer dizer ‘por que ela estima a relação verdadeira entre Y e X’, entramos em probabilidade e inferência. - E se você quer dizer ‘por que ela prevê bem novos dados’, aí já estamos em otimização e machine learning.\nEntão… a resposta depende do quadro em que você está!\nE é exatamente isso que eu quero construir neste curso: te nivelar por cima para você atingir o quadro conceitual onde tudo isso se conecta."
  },
  {
    "objectID": "index.html#objetivo-do-curso",
    "href": "index.html#objetivo-do-curso",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "🎯 Objetivo do Curso ",
    "text": "🎯 Objetivo do Curso \nDar uma formação sólida em Matemática, Estatística e Machine Learning,\ntendo a Regressão Linear como fio condutor para unir teoria, geometria e prática.\nVocê vai compreender:\n\nO mundo da Estatística (inferência) - como estimamos, testamos e interpretamos relações entre variáveis.\n\nO mundo do Machine Learning (predição e otimização) - como treinamos modelos para prever e generalizar.\n\nE que ambos partem da mesma base: álgebra linear + probabilidade + otimização."
  },
  {
    "objectID": "index.html#por-que-este-curso-é-diferente-e-por-que-dois-sabores",
    "href": "index.html#por-que-este-curso-é-diferente-e-por-que-dois-sabores",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "🤔 Por que este curso é diferente e Por que “dois sabores”?",
    "text": "🤔 Por que este curso é diferente e Por que “dois sabores”?\nA maioria dos cursos ensina regressão como uma receita.\nAqui, você vai entender o porquê de cada passo - e ver como a matemática, quando bem explicada, se torna clara, visual e até bonita.\n\n👁️ Visual: você vai enxergar o que as equações representam no espaço.\n\n🔢 Matemático: aprender o essencial de álgebra, probabilidade e otimização no contexto certo.\n\n💡 Aplicado: ver a teoria funcionando em Python e em dados reais.\n\n🎯 Conectado: entender como Estatística e Machine Learning são duas formas de olhar o mesmo problema.\n\nAlém disso, você vai aprender a mesma Regressão Linear sob dois paradigmas:\n- Estatístico (inferência e causalidade) — entender por que e como as variáveis se relacionam.\n- Computacional (predição e otimização) — treinar modelos que funcionam bem em novos dados.\nAlgum desses dois modos de pensar aparecem em praticamente todas as indústrias:\n\n🏥 Educação, Saúde e Epidemiologia: regressão é usada para estimar o efeito de medicamentos, identificar fatores de risco e ajustar por variáveis de confusão - foco na inferência causal.\n\n🛒 E-commerce e Marketing: usada para prever vendas, calcular propensão à compra ou estimar o impacto de campanhas - foco na predição e otimização.\n\n⚙️ Engenharia e IoT: modelos lineares ajudam a prever falhas, calibrar sensores e otimizar desempenho de máquinas - combinando modelagem estatística e preditiva.\n\nEm todos esses contextos, a matemática é a mesma - o que muda é o propósito: explicar ou prever."
  },
  {
    "objectID": "index.html#pré-requisitos",
    "href": "index.html#pré-requisitos",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "🧩 Pré-requisitos ",
    "text": "🧩 Pré-requisitos \nEste curso foi feito para quem quer aprender Regressão Linear de verdade - da base à aplicação prática, mesmo sem formação formal em Estatística ou Engenharia.\n\n🎓 Conhecimentos desejáveis\n\nMatemática básica do ensino médio: frações, potências e equações lineares simples.\n\nFunções e gráficos: o que significa uma reta, inclinação, intercepto e plano \\(x\\)-\\(y\\).\n\nLeitura em inglês técnico: termos como dataset, model, gradient.\n\nCuriosidade com programação: Python é bem-vindo, mas não obrigatório."
  },
  {
    "objectID": "index.html#conteúdo-completo",
    "href": "index.html#conteúdo-completo",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "📘 Conteúdo Completo ",
    "text": "📘 Conteúdo Completo \nO curso foi desenhado para que cada conceito matemático surja como uma resposta natural a uma pergunta prática.\nVocê não vai decorar fórmulas: vai entender por que elas existem, o que representam e como se conectam.\n\nEstrutura Geral\n\n\n\nMódulo\nTema\nÊnfase\n\n\n\n\n0\nO que é modelar dados\nIntuição e motivação\n\n\n1\nFundamentos Matemáticos\nÁlgebra Linear + Otimização\n\n\n2\nFundamentos Estatísticos\nProbabilidade + Inferência\n\n\n3\nRegressão Linear (Estatística)\nOLS e interpretação\n\n\n4\nRegressão Linear (ML)\nGradient Descent e predição\n\n\n\n\n\nÁlgebra Linear: a casa da regressão linear\n-&gt; Como uma equação vira um modelo? Onde a regressão realmente “vive”?\n\nCada coluna do dataset (\\(X_1, X_2, ..., X_p\\)) é uma variável explicativa, uma direção em um espaço vetorial. O conjunto dessas colunas forma o subespaço de colunas de \\(X\\) - é dentro dele que o modelo tenta “reconstruir” \\(Y\\), a variável que queremos explicar.\nO dataset como matriz: um conjunto de observações pode ser escrito como uma matriz \\(X\\) de tamanho \\(n \\times p\\), onde cada linha representa uma observação e cada coluna, uma variável. É aqui que o dataset ganha forma geométrica: um objeto que podemos manipular, projetar e decompor.\nEspaço e subespaço: representam todas as combinações possíveis das variáveis. Mostram até onde o modelo pode ir - o que ele consegue e o que jamais explicará.\nBase e dimensão: indicam quantas variáveis realmente trazem informação nova, e quando algumas apenas repetem o que outras já dizem (multicolinearidade).\nProjeção: ajustar a regressão é projetar \\(Y\\) sobre o espaço gerado por \\(X\\) - encontrar a melhor combinação linear das colunas de \\(X\\) que aproxima \\(Y\\).\nOrtogonalidade e resíduos: os resíduos são perpendiculares a esse espaço; isso significa que o modelo já extraiu tudo o que \\(X\\) podia oferecer.\nSolução matricial: \\(\\hat{\\beta} = (X'X)^{-1}X'Y\\) expressa exatamente o processo de projeção de \\(Y\\) sobre o espaço das colunas de \\(X\\). A fórmula mostra como o modelo “combina” as colunas de \\(X\\) para construir a versão de \\(Y\\) mais próxima possível - \\(\\hat{Y} = X\\hat{\\beta}\\).\n\n\nA regressão linear é, geometricamente, a melhor projeção possível de \\(Y\\) no espaço definido por \\(X\\).\n\n\n\n\nProbabilidade Clássica - a casa da incerteza presente nos dados\n\nAntes, \\(Y\\) e \\(X\\) eram vetores no espaço. Agora, eles passam a ser variáveis aleatórias (random variables) - porque agora a necessidade é entender o que é incerteza, amostra, etc.\n\nA partir daqui, tratamos o modelo como uma crença formal sobre como os dados são gerados: um Data Generating Process (DGP) ou um “mecanismo gerador dos dados”. É o elo entre a realidade e o modelo: o que assumimos ser verdadeiro sobre o processo que produz as observações, ou seja, os dados.\n\nO DGP como mecanismo:\nSupomos que existe uma relação verdadeira na população que explica como X se relaciona com Y, e que nossa amostra é apenas uma manifestação aleatória desse processo. É aqui que nasce a noção de incerteza: e de que “modelo” significa assumir algo sobre o mundo.\nVariáveis Aleatórias (random variables):\nAs colunas de \\(X\\) e o vetor \\(Y\\) na Álgebra Linear agora são variáveis aleatórias, ou seja, objetos que assumem valores diferentes a cada extração do DGP, como uma certa probabilidade atribuída a cada valor. Tipo quando jogamos uma moeda e cada valor tem chance 50% de aparecer. Esse conceito transforma o dataset \\((Y, X)\\) abstrato em uma realização de algo maior: uma amostra aleatória.\nTipos de variáveis:\nO tipo de variável define o espaço onde ela vive - um conceito que vem da Matemática mais refinada:\n\nQuando o conjunto de valores possíveis é contável - finito (como \\({0,1}\\)) ou infinito mas enumerável (como os naturais \\({1,2,3,...}\\)) - dizemos que a variável é discreta.\nExemplo: número de filhos, quantidade de produtos vendidos.\n\nQuando o conjunto de valores é infinito e não enumerável, dizemos que a variável é contínua. Exemplo: altura, renda, temperatura.\n\nEssa diferença muda completamente a forma da distribuição - e, portanto, do modelo:\n\nSe \\(Y\\) é contínua → usamos Regressão Linear.\n\nSe \\(Y\\) é binária (0/1) → Regressão Logística.\n\nSe alguma variável \\(X\\) é categórica → representamos por dummies (1 para presença, 0 para ausência), criando novas dimensões no espaço vetorial.\n\n💡 Nota:\nUma outra confusão vem do fato de que nem toda variável discreta é “categórica”. Uma variável pode ser discreta com ou sem ordem entre os valores:\n\nOrdinal (há ordem, como nível de satisfação: “baixo”, “médio”, “alto”);\n\nNominal (sem ordem, como “sexo” ou “cor dos olhos”).\n\n\nEntender a natureza da variável evita erros conceituais - e garante que cada tipo seja modelado de forma coerente com sua estrutura matemática.\n\nDistribuição e incerteza:\nCada variável aleatória tem uma distribuição, que descreve a probabilidade de cada valor possível. A distribuição é a forma matemática de expressar a incerteza e o alicerce de todo raciocínio estatístico.\nAmostra aleatória:\nAs observações que temos são uma amostra independente do DGP. Isso legitima usar os dados observados para aprender sobre a população.\nModelo probabilístico:\nEspecificamos a crença de que:\n\\[Y_i = \\beta_0 + \\beta_1 X_{i1} + \\cdots + \\beta_p X_{ip} + \\varepsilon_i,\\]\nonde \\(\\varepsilon_i\\) representa o componente aleatório, com \\(\\mathbb{E}[\\varepsilon_i] = 0\\) e \\(\\text{Var}(\\varepsilon_i) = \\sigma^2\\).\n\nO modelo agora é mais do que uma reta - é uma afirmação probabilística sobre o comportamento de \\(Y\\) dado \\(X\\).\n\nModelo estatístico:\nÉ o conjunto de todos os possíveis DGPs compatíveis com as suposições (linearidade, homocedasticidade, independência, normalidade dos erros). Isso define os limites do que podemos inferir. Quando essas suposições quebram, o modelo deixa de representar o mundo que imaginamos.\n\n\n\n🎯 A probabilidade dá à regressão um novo significado:\nnão mais “qual reta cabe melhor nos pontos”, mas\n“qual mecanismo plausível pode ter gerado esses pontos”.\n\n\n\nInferência Estatística\n\nOLS como melhor estimador linear não viesado (Gauss–Markov)\n\nErro padrão, intervalo de confiança e teste t\n\nTeste F e interpretação global do modelo\n\nHipóteses e p-valores\n\nDiagnóstico de resíduos e suposições do modelo\n\nIdeia de Causalidade vs. Correlação - quando o \\(\\beta\\) é causal?\n\n\n\nOtimização\n\nRevisão de derivadas e gradiente vetorial\n\nFunções convexas e mínimos locais\n\nDerivada matricial da soma dos quadrados\n\nGradient Descent: passo de atualização e intuição geométrica\n\nFunção de perda (Loss Function) e erro empírico\n\nIntrodução à regularização: Ridge e LASSO\n\nConvergência, taxa de aprendizado e visualização do gradiente"
  },
  {
    "objectID": "index.html#formato",
    "href": "index.html#formato",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "🧱 Formato",
    "text": "🧱 Formato\n\nVídeos curtos e progressivos, lançados semanalmente\n\nExercícios práticos em Python\n\nVisualizações geométricas e intuições claras\n\nComunidade e feedback"
  },
  {
    "objectID": "index.html#inscreva-se",
    "href": "index.html#inscreva-se",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "📝 Inscreva-se ",
    "text": "📝 Inscreva-se \nQuer ser avisado quando abrirem as inscrições?\n\nCarregando…\n\n\n\n\n\n\nCaio Velasco é Engenheiro Mecânico Cum Laude pela UFRJ e Mestre em Economia e Políticas Públicas pela UCLA, com bolsa da Fundação Lemann. Atualmente mora em Barcelona, na Espanha.\nDepois de pausar um doutorado em Economia na Holanda durante a pandemia, passou a atuar remotamente em Projetos de Engenharia e Ciência de Dados, ajudando empresas dos EUA, Europa e Brasil a construírem plataformas modernas e preparar modelos para responder perguntas de negócio. Porém, a paixão por ensinar é o que mais o motiva.\nAntes disso, trabalhou com FinTech e EdTech e fundou o MePrepara, plataforma online que ensinou matemática para as provas GRE e GMAT.\nReconhecido por instituições como UCLA, Yale, Fundação Lemann, General Electric Foundation e Club of Rome na Suiça, Caio combina engenharia, economia e educação - e acredita que entender a matemática por trás dos modelos sem perder a intuição e a aplicação prática é essencial.\n\n💡 “Meu objetivo é ensinar com clareza e propósito - conectando teoria, intuição e aplicação prática.”"
  }
]