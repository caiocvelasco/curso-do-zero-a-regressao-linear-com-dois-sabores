[
  {
    "objectID": "index.html#por-que-este-curso-é-diferente",
    "href": "index.html#por-que-este-curso-é-diferente",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "🧠 Por que este curso é diferente",
    "text": "🧠 Por que este curso é diferente\nA maioria dos cursos ensina regressão como uma receita.\nAqui, você vai entender o porquê de cada passo - e ver como a matemática, quando bem explicada, se torna clara, visual e até bonita.\n\n👁️ Visual: você vai enxergar o que as equações representam no espaço.\n\n🔢 Matemático: aprender o essencial de álgebra, probabilidade e otimização no contexto certo.\n\n💡 Aplicado: ver a teoria funcionando em Python e em dados reais.\n\n🎯 Conectado: entender como Estatística e Machine Learning são duas formas de olhar o mesmo problema.\n\n\nAqui você vai aprender o que nenhum curso te ensina. A mesma regressão linear, vista por dois mundos:\n- o da Estatística (inferência e causalidade) e\n- o do Machine Learning (predição e otimização)."
  },
  {
    "objectID": "index.html#pré-requisitos",
    "href": "index.html#pré-requisitos",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "🧩 Pré-requisitos ",
    "text": "🧩 Pré-requisitos \nEste curso foi feito para quem quer aprender Regressão Linear de verdade - da base à aplicação prática, mesmo sem formação formal em Estatística ou Engenharia.\n\n🎓 Conhecimentos desejáveis (não obrigatórios)\n\nMatemática básica do ensino médio: frações, potências e equações lineares simples.\n\nFunções e gráficos: o que significa uma reta, inclinação, intercepto e plano \\(x\\)-\\(y\\).\n\nLeitura em inglês técnico: termos como dataset, model, gradient.\n\nCuriosidade com programação: Python é bem-vindo, mas não obrigatório."
  },
  {
    "objectID": "index.html#objetivo-do-curso",
    "href": "index.html#objetivo-do-curso",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "🎯 Objetivo do Curso",
    "text": "🎯 Objetivo do Curso\nDar uma formação sólida em Matemática, Estatística e Machine Learning,\ntendo a Regressão Linear como fio condutor para unir teoria, geometria e prática.\nVocê vai compreender:\n\nO mundo da inferência - como estimamos, testamos e interpretamos relações entre variáveis.\n\nO mundo da predição - como treinamos modelos para prever e generalizar.\n\nE que ambos partem da mesma base: álgebra linear + probabilidade + otimização."
  },
  {
    "objectID": "index.html#estrutura-didática",
    "href": "index.html#estrutura-didática",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "🚀 Estrutura Didática ",
    "text": "🚀 Estrutura Didática \n\n\n\nMódulo\nTema\nÊnfase\n\n\n\n\n0\nO que é modelar dados\nIntuição e motivação\n\n\n1\nFundamentos Matemáticos\nÁlgebra Linear + Otimização\n\n\n2\nFundamentos Estatísticos\nProbabilidade + Inferência\n\n\n3\nRegressão Linear (Estatística)\nOLS e interpretação\n\n\n4\nRegressão Linear (ML)\nGradient Descent e predição"
  },
  {
    "objectID": "index.html#conteúdo-completo",
    "href": "index.html#conteúdo-completo",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "📘 Conteúdo Completo",
    "text": "📘 Conteúdo Completo\nCada pilar é construído com foco em intuição, formalização e prática.\n\nÁlgebra Linear\n\nVetores, matrizes e operações elementares\n\nProduto interno e projeções ortogonais\n\nSubespaço de colunas e interpretação geométrica de \\(X\\beta\\)\nSolução matricial da regressão linear:\n\\(\\hat{\\beta} = (X'X)^{-1}X'Y\\)\n\nInterpretação de resíduos como vetores ortogonais\n\nRepresentação gráfica em 2D e 3D\n\n\n\nProbabilidade Clássica\n\nVariáveis aleatórias e distribuições\n\nEsperança, variância e covariância\n\nLei dos Grandes Números e intuição da média amostral\n\nIntrodução ao conceito de ruído: \\(\\varepsilon_i \\sim (0, \\sigma^2)\\)\n\nConstrução intuitiva do modelo probabilístico:\n\\(Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\\)\n\n\n\nInferência Estatística\n\nOLS como melhor estimador linear não viesado (Gauss–Markov)\n\nErro padrão, intervalo de confiança e teste t\n\nTeste F e interpretação global do modelo\n\nHipóteses e p-valores\n\nDiagnóstico de resíduos e suposições do modelo\n\nIdeia: Causalidade vs. Correlação - quando o \\(\\beta\\) é causal?\n\n\n\nOtimização\n\nRevisão de derivadas e gradiente vetorial\n\nFunções convexas e mínimos locais\n\nDerivada matricial da soma dos quadrados\n\nGradient Descent: passo de atualização e intuição geométrica\n\nFunção de perda (Loss Function) e erro empírico\n\nIntrodução à regularização: Ridge e LASSO\n\nConvergência, taxa de aprendizado e visualização do gradiente"
  },
  {
    "objectID": "index.html#por-que-dois-sabores",
    "href": "index.html#por-que-dois-sabores",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "💡 Por que “dois sabores”?",
    "text": "💡 Por que “dois sabores”?\nPorque você vai aprender a mesma regressão linear sob dois paradigmas:\n- Estatístico (inferência e causalidade) e\n- Computacional (predição e otimização)."
  },
  {
    "objectID": "index.html#formato",
    "href": "index.html#formato",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "🧱 Formato",
    "text": "🧱 Formato\n\nVídeos curtos e progressivos, lançados semanalmente\n\nExercícios práticos em Python\n\nVisualizações geométricas e intuições claras\n\nComunidade e feedback"
  },
  {
    "objectID": "index.html#inscreva-se",
    "href": "index.html#inscreva-se",
    "title": "Do Zero à Regressão Linear - com Dois Sabores",
    "section": "📝 Inscreva-se ",
    "text": "📝 Inscreva-se \nQuer ser avisado quando abrirem as inscrições?\n\nCarregando…\n\n\n\n\n\n\nCaio Velasco é Engenheiro Mecânico Cum Laude pela UFRJ e Mestre em Economia e Políticas Públicas pela UCLA, com bolsa da Fundação Lemann. Atualmente mora em Barcelona, na Espanha.\nDepois de pausar um doutorado em Economia na Holanda durante a pandemia, passou a atuar remotamente em Projetos de Engenharia e Ciência de Dados, ajudando empresas dos EUA, Europa e Brasil a construírem plataformas modernas e preparar modelos para responder perguntas de negócio. Porém, a paixão por ensinar é o que mais o motiva.\nAntes disso, trabalhou com FinTech e EdTech e fundou o MePrepara, plataforma online que ensinou matemática para as provas GRE e GMAT.\nReconhecido por instituições como UCLA, Yale, Fundação Lemann, General Electric Foundation e Club of Rome na Suiça, Caio combina engenharia, economia e educação - e acredita que entender a matemática por trás dos modelos sem perder a intuição e a aplicação prática é essencial.\n\n💡 “Meu objetivo é ensinar com clareza e propósito - conectando teoria, intuição e aplicação prática.”"
  }
]