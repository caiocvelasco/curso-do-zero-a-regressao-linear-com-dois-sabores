[
  {
    "objectID": "index.html#por-que-este-curso-Ã©-diferente",
    "href": "index.html#por-que-este-curso-Ã©-diferente",
    "title": "Do Zero Ã  RegressÃ£o Linear - com Dois Sabores",
    "section": "ğŸ§  Por que este curso Ã© diferente",
    "text": "ğŸ§  Por que este curso Ã© diferente\nA maioria dos cursos ensina regressÃ£o como uma receita.\nAqui, vocÃª vai entender o porquÃª de cada passo - e ver como a matemÃ¡tica, quando bem explicada, se torna clara, visual e atÃ© bonita.\n\nğŸ‘ï¸ Visual: vocÃª vai enxergar o que as equaÃ§Ãµes representam no espaÃ§o.\n\nğŸ”¢ MatemÃ¡tico: aprender o essencial de Ã¡lgebra, probabilidade e otimizaÃ§Ã£o no contexto certo.\n\nğŸ’¡ Aplicado: ver a teoria funcionando em Python e em dados reais.\n\nğŸ¯ Conectado: entender como EstatÃ­stica e Machine Learning sÃ£o duas formas de olhar o mesmo problema.\n\n\nAqui vocÃª vai aprender o que nenhum curso te ensina. A mesma regressÃ£o linear, vista por dois mundos:\n- o da EstatÃ­stica (inferÃªncia e causalidade) e\n- o do Machine Learning (prediÃ§Ã£o e otimizaÃ§Ã£o)."
  },
  {
    "objectID": "index.html#prÃ©-requisitos",
    "href": "index.html#prÃ©-requisitos",
    "title": "Do Zero Ã  RegressÃ£o Linear - com Dois Sabores",
    "section": "ğŸ§© PrÃ©-requisitos ",
    "text": "ğŸ§© PrÃ©-requisitos \nEste curso foi feito para quem quer aprender RegressÃ£o Linear de verdade - da base Ã  aplicaÃ§Ã£o prÃ¡tica, mesmo sem formaÃ§Ã£o formal em EstatÃ­stica ou Engenharia.\n\nğŸ“ Conhecimentos desejÃ¡veis (nÃ£o obrigatÃ³rios)\n\nMatemÃ¡tica bÃ¡sica do ensino mÃ©dio: fraÃ§Ãµes, potÃªncias e equaÃ§Ãµes lineares simples.\n\nFunÃ§Ãµes e grÃ¡ficos: o que significa uma reta, inclinaÃ§Ã£o, intercepto e plano \\(x\\)-\\(y\\).\n\nLeitura em inglÃªs tÃ©cnico: termos como dataset, model, gradient.\n\nCuriosidade com programaÃ§Ã£o: Python Ã© bem-vindo, mas nÃ£o obrigatÃ³rio."
  },
  {
    "objectID": "index.html#objetivo-do-curso",
    "href": "index.html#objetivo-do-curso",
    "title": "Do Zero Ã  RegressÃ£o Linear - com Dois Sabores",
    "section": "ğŸ¯ Objetivo do Curso",
    "text": "ğŸ¯ Objetivo do Curso\nDar uma formaÃ§Ã£o sÃ³lida em MatemÃ¡tica, EstatÃ­stica e Machine Learning,\ntendo a RegressÃ£o Linear como fio condutor para unir teoria, geometria e prÃ¡tica.\nVocÃª vai compreender:\n\nO mundo da inferÃªncia - como estimamos, testamos e interpretamos relaÃ§Ãµes entre variÃ¡veis.\n\nO mundo da prediÃ§Ã£o - como treinamos modelos para prever e generalizar.\n\nE que ambos partem da mesma base: Ã¡lgebra linear + probabilidade + otimizaÃ§Ã£o."
  },
  {
    "objectID": "index.html#estrutura-didÃ¡tica",
    "href": "index.html#estrutura-didÃ¡tica",
    "title": "Do Zero Ã  RegressÃ£o Linear - com Dois Sabores",
    "section": "ğŸš€ Estrutura DidÃ¡tica ",
    "text": "ğŸš€ Estrutura DidÃ¡tica \n\n\n\nMÃ³dulo\nTema\nÃŠnfase\n\n\n\n\n0\nO que Ã© modelar dados\nIntuiÃ§Ã£o e motivaÃ§Ã£o\n\n\n1\nFundamentos MatemÃ¡ticos\nÃlgebra Linear + OtimizaÃ§Ã£o\n\n\n2\nFundamentos EstatÃ­sticos\nProbabilidade + InferÃªncia\n\n\n3\nRegressÃ£o Linear (EstatÃ­stica)\nOLS e interpretaÃ§Ã£o\n\n\n4\nRegressÃ£o Linear (ML)\nGradient Descent e prediÃ§Ã£o"
  },
  {
    "objectID": "index.html#conteÃºdo-completo",
    "href": "index.html#conteÃºdo-completo",
    "title": "Do Zero Ã  RegressÃ£o Linear - com Dois Sabores",
    "section": "ğŸ“˜ ConteÃºdo Completo",
    "text": "ğŸ“˜ ConteÃºdo Completo\nCada pilar Ã© construÃ­do com foco em intuiÃ§Ã£o, formalizaÃ§Ã£o e prÃ¡tica.\n\nÃlgebra Linear\n\nVetores, matrizes e operaÃ§Ãµes elementares\n\nProduto interno e projeÃ§Ãµes ortogonais\n\nSubespaÃ§o de colunas e interpretaÃ§Ã£o geomÃ©trica de \\(X\\beta\\)\nSoluÃ§Ã£o matricial da regressÃ£o linear:\n\\(\\hat{\\beta} = (X'X)^{-1}X'Y\\)\n\nInterpretaÃ§Ã£o de resÃ­duos como vetores ortogonais\n\nRepresentaÃ§Ã£o grÃ¡fica em 2D e 3D\n\n\n\nProbabilidade ClÃ¡ssica\n\nVariÃ¡veis aleatÃ³rias e distribuiÃ§Ãµes\n\nEsperanÃ§a, variÃ¢ncia e covariÃ¢ncia\n\nLei dos Grandes NÃºmeros e intuiÃ§Ã£o da mÃ©dia amostral\n\nIntroduÃ§Ã£o ao conceito de ruÃ­do: \\(\\varepsilon_i \\sim (0, \\sigma^2)\\)\n\nConstruÃ§Ã£o intuitiva do modelo probabilÃ­stico:\n\\(Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\\)\n\n\n\nInferÃªncia EstatÃ­stica\n\nOLS como melhor estimador linear nÃ£o viesado (Gaussâ€“Markov)\n\nErro padrÃ£o, intervalo de confianÃ§a e teste t\n\nTeste F e interpretaÃ§Ã£o global do modelo\n\nHipÃ³teses e p-valores\n\nDiagnÃ³stico de resÃ­duos e suposiÃ§Ãµes do modelo\n\nIdeia: Causalidade vs.Â CorrelaÃ§Ã£o - quando o \\(\\beta\\) Ã© causal?\n\n\n\nOtimizaÃ§Ã£o\n\nRevisÃ£o de derivadas e gradiente vetorial\n\nFunÃ§Ãµes convexas e mÃ­nimos locais\n\nDerivada matricial da soma dos quadrados\n\nGradient Descent: passo de atualizaÃ§Ã£o e intuiÃ§Ã£o geomÃ©trica\n\nFunÃ§Ã£o de perda (Loss Function) e erro empÃ­rico\n\nIntroduÃ§Ã£o Ã  regularizaÃ§Ã£o: Ridge e LASSO\n\nConvergÃªncia, taxa de aprendizado e visualizaÃ§Ã£o do gradiente"
  },
  {
    "objectID": "index.html#por-que-dois-sabores",
    "href": "index.html#por-que-dois-sabores",
    "title": "Do Zero Ã  RegressÃ£o Linear - com Dois Sabores",
    "section": "ğŸ’¡ Por que â€œdois saboresâ€?",
    "text": "ğŸ’¡ Por que â€œdois saboresâ€?\nPorque vocÃª vai aprender a mesma regressÃ£o linear sob dois paradigmas:\n- EstatÃ­stico (inferÃªncia e causalidade) e\n- Computacional (prediÃ§Ã£o e otimizaÃ§Ã£o)."
  },
  {
    "objectID": "index.html#formato",
    "href": "index.html#formato",
    "title": "Do Zero Ã  RegressÃ£o Linear - com Dois Sabores",
    "section": "ğŸ§± Formato",
    "text": "ğŸ§± Formato\n\nVÃ­deos curtos e progressivos, lanÃ§ados semanalmente\n\nExercÃ­cios prÃ¡ticos em Python\n\nVisualizaÃ§Ãµes geomÃ©tricas e intuiÃ§Ãµes claras\n\nComunidade e feedback"
  },
  {
    "objectID": "index.html#inscreva-se",
    "href": "index.html#inscreva-se",
    "title": "Do Zero Ã  RegressÃ£o Linear - com Dois Sabores",
    "section": "ğŸ“ Inscreva-se ",
    "text": "ğŸ“ Inscreva-se \nQuer ser avisado quando abrirem as inscriÃ§Ãµes?\n\nCarregandoâ€¦\n\n\n\n\n\n\nCaio Velasco Ã© Engenheiro MecÃ¢nico Cum Laude pela UFRJ e Mestre em Economia e PolÃ­ticas PÃºblicas pela UCLA, com bolsa da FundaÃ§Ã£o Lemann. Atualmente mora em Barcelona, na Espanha.\nDepois de pausar um doutorado em Economia na Holanda durante a pandemia, passou a atuar remotamente em Projetos de Engenharia e CiÃªncia de Dados, ajudando empresas dos EUA, Europa e Brasil a construÃ­rem plataformas modernas e preparar modelos para responder perguntas de negÃ³cio. PorÃ©m, a paixÃ£o por ensinar Ã© o que mais o motiva.\nAntes disso, trabalhou com FinTech e EdTech e fundou o MePrepara, plataforma online que ensinou matemÃ¡tica para as provas GRE e GMAT.\nReconhecido por instituiÃ§Ãµes como UCLA, Yale, FundaÃ§Ã£o Lemann, General Electric Foundation e Club of Rome na SuiÃ§a, Caio combina engenharia, economia e educaÃ§Ã£o - e acredita que entender a matemÃ¡tica por trÃ¡s dos modelos sem perder a intuiÃ§Ã£o e a aplicaÃ§Ã£o prÃ¡tica Ã© essencial.\n\nğŸ’¡ â€œMeu objetivo Ã© ensinar com clareza e propÃ³sito - conectando teoria, intuiÃ§Ã£o e aplicaÃ§Ã£o prÃ¡tica.â€"
  }
]